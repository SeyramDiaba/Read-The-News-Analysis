{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64a51bf3",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6b35e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from articles import articles\n",
    "from preprocessing import preprocess_text\n",
    "\n",
    "# import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer,TfidfVectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549bcfbe",
   "metadata": {},
   "source": [
    "## View Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c5845ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISLAMABAD: Long queues of vehicles on fuel stations were visible in different parts of the country as the petrol became rare commodity on Thursday. Federal Minister for Petroleum Shahid Khaqan Abbasi says \"it may take up to ten days to bring the situation to normality\". He claimed that northern areas of Pakistan had been facing the petrol shortage. The minister cited the recent decline in petroleum prices and delay in a shipment as reasons for the shortage.He said situation would improve as soon as shipment reached Pakistan. Sources told Geo News hat due to financial restraints the Pakistan State Oil has been unable import petrol.\n"
     ]
    }
   ],
   "source": [
    "# view article\n",
    "print(articles[3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148a1236",
   "metadata": {},
   "source": [
    "### Preprocess articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dada2822",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_articles = [preprocess_text(article) for article in articles]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cb1df0",
   "metadata": {},
   "source": [
    "## initialize and fit CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c11c6b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 169)\t4\n",
      "  (0, 316)\t6\n",
      "  (0, 287)\t1\n",
      "  (0, 132)\t3\n",
      "  (0, 139)\t2\n",
      "  (0, 74)\t1\n",
      "  (0, 321)\t4\n",
      "  (0, 39)\t1\n",
      "  (0, 87)\t1\n",
      "  (0, 242)\t2\n",
      "  (0, 324)\t3\n",
      "  (0, 110)\t4\n",
      "  (0, 44)\t3\n",
      "  (0, 227)\t1\n",
      "  (0, 50)\t1\n",
      "  (0, 89)\t1\n",
      "  (0, 192)\t1\n",
      "  (0, 258)\t2\n",
      "  (0, 152)\t4\n",
      "  (0, 230)\t1\n",
      "  (0, 239)\t1\n",
      "  (0, 236)\t2\n",
      "  (0, 111)\t1\n",
      "  (0, 129)\t1\n",
      "  (0, 210)\t1\n",
      "  :\t:\n",
      "  (9, 170)\t2\n",
      "  (9, 352)\t2\n",
      "  (9, 27)\t1\n",
      "  (9, 292)\t1\n",
      "  (9, 5)\t1\n",
      "  (9, 29)\t1\n",
      "  (9, 70)\t1\n",
      "  (9, 317)\t1\n",
      "  (9, 211)\t1\n",
      "  (9, 28)\t1\n",
      "  (9, 64)\t1\n",
      "  (9, 79)\t1\n",
      "  (9, 51)\t1\n",
      "  (9, 26)\t1\n",
      "  (9, 334)\t1\n",
      "  (9, 133)\t1\n",
      "  (9, 351)\t2\n",
      "  (9, 126)\t1\n",
      "  (9, 303)\t1\n",
      "  (9, 118)\t1\n",
      "  (9, 103)\t1\n",
      "  (9, 263)\t1\n",
      "  (9, 23)\t1\n",
      "  (9, 17)\t1\n",
      "  (9, 183)\t1\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "counts = vectorizer.fit_transform(processed_articles)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72964e35",
   "metadata": {},
   "source": [
    "## Convert counts to tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c18bc5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 343)\t5.3653720810928105\n",
      "  (0, 339)\t2.7047480922384253\n",
      "  (0, 333)\t2.01160091167848\n",
      "  (0, 326)\t2.2992829841302607\n",
      "  (0, 325)\t2.7047480922384253\n",
      "  (0, 324)\t8.114244276715276\n",
      "  (0, 321)\t4.3812407192173\n",
      "  (0, 316)\t6.0\n",
      "  (0, 315)\t1.3184537311185345\n",
      "  (0, 309)\t2.2992829841302607\n",
      "  (0, 290)\t2.01160091167848\n",
      "  (0, 287)\t2.2992829841302607\n",
      "  (0, 275)\t3.6020120863864538\n",
      "  (0, 270)\t2.7047480922384253\n",
      "  (0, 268)\t2.7047480922384253\n",
      "  (0, 261)\t2.2992829841302607\n",
      "  (0, 259)\t2.7047480922384253\n",
      "  (0, 258)\t5.4094961844768505\n",
      "  (0, 242)\t5.4094961844768505\n",
      "  (0, 239)\t2.7047480922384253\n",
      "  (0, 236)\t3.5769147207285403\n",
      "  (0, 235)\t2.7047480922384253\n",
      "  (0, 230)\t2.2992829841302607\n",
      "  (0, 227)\t2.2992829841302607\n",
      "  (0, 224)\t2.2992829841302607\n",
      "  :\t:\n",
      "  (9, 214)\t1.095310179804325\n",
      "  (9, 211)\t2.7047480922384253\n",
      "  (9, 183)\t2.7047480922384253\n",
      "  (9, 170)\t5.4094961844768505\n",
      "  (9, 133)\t2.7047480922384253\n",
      "  (9, 126)\t2.7047480922384253\n",
      "  (9, 118)\t2.7047480922384253\n",
      "  (9, 117)\t1.6061358035703155\n",
      "  (9, 103)\t2.7047480922384253\n",
      "  (9, 79)\t2.7047480922384253\n",
      "  (9, 70)\t2.7047480922384253\n",
      "  (9, 64)\t2.7047480922384253\n",
      "  (9, 54)\t5.4094961844768505\n",
      "  (9, 51)\t2.7047480922384253\n",
      "  (9, 33)\t2.7047480922384253\n",
      "  (9, 30)\t1.095310179804325\n",
      "  (9, 29)\t2.7047480922384253\n",
      "  (9, 28)\t2.7047480922384253\n",
      "  (9, 27)\t2.7047480922384253\n",
      "  (9, 26)\t2.7047480922384253\n",
      "  (9, 23)\t2.7047480922384253\n",
      "  (9, 17)\t2.7047480922384253\n",
      "  (9, 13)\t1.3184537311185345\n",
      "  (9, 11)\t2.2992829841302607\n",
      "  (9, 5)\t2.7047480922384253\n"
     ]
    }
   ],
   "source": [
    "transformer = TfidfTransformer(norm = None)\n",
    "tfidf_scores_transformed = transformer.fit_transform(counts) \n",
    "print(tfidf_scores_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed763a7e",
   "metadata": {},
   "source": [
    "##  Initialize and fit TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e7cb3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 188)\t2.2992829841302607\n",
      "  (0, 77)\t2.7047480922384253\n",
      "  (0, 339)\t2.7047480922384253\n",
      "  (0, 71)\t2.7047480922384253\n",
      "  (0, 325)\t2.7047480922384253\n",
      "  (0, 58)\t5.4094961844768505\n",
      "  (0, 127)\t2.7047480922384253\n",
      "  (0, 207)\t2.7047480922384253\n",
      "  (0, 62)\t2.7047480922384253\n",
      "  (0, 270)\t2.7047480922384253\n",
      "  (0, 333)\t2.01160091167848\n",
      "  (0, 315)\t1.3184537311185345\n",
      "  (0, 4)\t2.2992829841302607\n",
      "  (0, 66)\t2.01160091167848\n",
      "  (0, 224)\t2.2992829841302607\n",
      "  (0, 61)\t2.7047480922384253\n",
      "  (0, 186)\t2.7047480922384253\n",
      "  (0, 53)\t2.7047480922384253\n",
      "  (0, 60)\t2.7047480922384253\n",
      "  (0, 42)\t5.4094961844768505\n",
      "  (0, 162)\t2.7047480922384253\n",
      "  (0, 235)\t2.7047480922384253\n",
      "  (0, 75)\t2.7047480922384253\n",
      "  (0, 1)\t2.7047480922384253\n",
      "  (0, 259)\t2.7047480922384253\n",
      "  :\t:\n",
      "  (9, 26)\t2.7047480922384253\n",
      "  (9, 51)\t2.7047480922384253\n",
      "  (9, 79)\t2.7047480922384253\n",
      "  (9, 64)\t2.7047480922384253\n",
      "  (9, 28)\t2.7047480922384253\n",
      "  (9, 211)\t2.7047480922384253\n",
      "  (9, 317)\t2.7047480922384253\n",
      "  (9, 70)\t2.7047480922384253\n",
      "  (9, 29)\t2.7047480922384253\n",
      "  (9, 5)\t2.7047480922384253\n",
      "  (9, 292)\t2.7047480922384253\n",
      "  (9, 27)\t2.7047480922384253\n",
      "  (9, 352)\t5.4094961844768505\n",
      "  (9, 170)\t5.4094961844768505\n",
      "  (9, 54)\t5.4094961844768505\n",
      "  (9, 33)\t2.7047480922384253\n",
      "  (9, 11)\t2.2992829841302607\n",
      "  (9, 117)\t1.6061358035703155\n",
      "  (9, 214)\t1.095310179804325\n",
      "  (9, 13)\t1.3184537311185345\n",
      "  (9, 217)\t1.4519851237430572\n",
      "  (9, 30)\t1.095310179804325\n",
      "  (9, 343)\t3.5769147207285403\n",
      "  (9, 275)\t2.4013413909243027\n",
      "  (9, 316)\t1.0\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(norm = None)\n",
    "tfidf_scores = vectorizer.fit_transform(processed_articles)\n",
    "print(tfidf_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fbe1d8",
   "metadata": {},
   "source": [
    "## Check if tf-idf scores are equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77b9560c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Are the tf-idf scores the same?\n",
      "0                             YES\n"
     ]
    }
   ],
   "source": [
    "if np.allclose(tfidf_scores_transformed.todense(), tfidf_scores.todense()):\n",
    "  print(pd.DataFrame({'Are the tf-idf scores the same?':['YES']}))\n",
    "else:\n",
    "  print(pd.DataFrame({'Are the tf-idf scores the same?':['No, something is wrong :(']}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32006292",
   "metadata": {},
   "source": [
    "## Get vocabulary of terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "751a9f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  feature_names = vectorizer.get_feature_names()\n",
    "except:\n",
    "  pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdcf175",
   "metadata": {},
   "source": [
    "##  Get article index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "678a777d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  article_index = [f\"Article {i+1}\" for i in range(len(articles))]\n",
    "except:\n",
    "  pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c1d240",
   "metadata": {},
   "source": [
    "## Create pandas DataFrame with word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc71829a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Article 1  Article 2  Article 3  Article 4  Article 5  Article 6  \\\n",
      "abbasi          0          0          0          1          0          0   \n",
      "abide           1          0          0          0          0          0   \n",
      "about           0          0          0          0          0          0   \n",
      "accord          0          0          1          0          0          0   \n",
      "add             1          0          0          0          0          0   \n",
      "...           ...        ...        ...        ...        ...        ...   \n",
      "world           0          0          0          0          0          3   \n",
      "would           0          0          0          1          0          0   \n",
      "year            0          1          0          0          0          0   \n",
      "yi              0          0          0          0          0          0   \n",
      "yuan            0          0          0          0          0          0   \n",
      "\n",
      "        Article 7  Article 8  Article 9  Article 10  \n",
      "abbasi          0          0          0           0  \n",
      "abide           0          0          0           0  \n",
      "about           1          0          0           0  \n",
      "accord          0          0          0           0  \n",
      "add             0          0          1           0  \n",
      "...           ...        ...        ...         ...  \n",
      "world           0          0          0           0  \n",
      "would           0          0          1           0  \n",
      "year            0          0          0           0  \n",
      "yi              0          0          0           2  \n",
      "yuan            0          0          0           2  \n",
      "\n",
      "[353 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  df_word_counts = pd.DataFrame(counts.T.todense(), index=feature_names, columns=article_index)\n",
    "  print(df_word_counts)\n",
    "except:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bfe449",
   "metadata": {},
   "source": [
    "## Create pandas DataFrame(s) with tf-idf scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d1933483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Article 1  Article 2  Article 3  Article 4  Article 5  Article 6  \\\n",
      "abbasi   0.000000   0.000000   0.000000   2.704748        0.0   0.000000   \n",
      "abide    2.704748   0.000000   0.000000   0.000000        0.0   0.000000   \n",
      "about    0.000000   0.000000   0.000000   0.000000        0.0   0.000000   \n",
      "accord   0.000000   0.000000   2.704748   0.000000        0.0   0.000000   \n",
      "add      2.299283   0.000000   0.000000   0.000000        0.0   0.000000   \n",
      "...           ...        ...        ...        ...        ...        ...   \n",
      "world    0.000000   0.000000   0.000000   0.000000        0.0   8.114244   \n",
      "would    0.000000   0.000000   0.000000   2.299283        0.0   0.000000   \n",
      "year     0.000000   2.704748   0.000000   0.000000        0.0   0.000000   \n",
      "yi       0.000000   0.000000   0.000000   0.000000        0.0   0.000000   \n",
      "yuan     0.000000   0.000000   0.000000   0.000000        0.0   0.000000   \n",
      "\n",
      "        Article 7  Article 8  Article 9  Article 10  \n",
      "abbasi   0.000000        0.0   0.000000    0.000000  \n",
      "abide    0.000000        0.0   0.000000    0.000000  \n",
      "about    2.704748        0.0   0.000000    0.000000  \n",
      "accord   0.000000        0.0   0.000000    0.000000  \n",
      "add      0.000000        0.0   2.299283    0.000000  \n",
      "...           ...        ...        ...         ...  \n",
      "world    0.000000        0.0   0.000000    0.000000  \n",
      "would    0.000000        0.0   2.299283    0.000000  \n",
      "year     0.000000        0.0   0.000000    0.000000  \n",
      "yi       0.000000        0.0   0.000000    5.409496  \n",
      "yuan     0.000000        0.0   0.000000    5.409496  \n",
      "\n",
      "[353 rows x 10 columns]\n",
      "        Article 1  Article 2  Article 3  Article 4  Article 5  Article 6  \\\n",
      "abbasi   0.000000   0.000000   0.000000   2.704748        0.0   0.000000   \n",
      "abide    2.704748   0.000000   0.000000   0.000000        0.0   0.000000   \n",
      "about    0.000000   0.000000   0.000000   0.000000        0.0   0.000000   \n",
      "accord   0.000000   0.000000   2.704748   0.000000        0.0   0.000000   \n",
      "add      2.299283   0.000000   0.000000   0.000000        0.0   0.000000   \n",
      "...           ...        ...        ...        ...        ...        ...   \n",
      "world    0.000000   0.000000   0.000000   0.000000        0.0   8.114244   \n",
      "would    0.000000   0.000000   0.000000   2.299283        0.0   0.000000   \n",
      "year     0.000000   2.704748   0.000000   0.000000        0.0   0.000000   \n",
      "yi       0.000000   0.000000   0.000000   0.000000        0.0   0.000000   \n",
      "yuan     0.000000   0.000000   0.000000   0.000000        0.0   0.000000   \n",
      "\n",
      "        Article 7  Article 8  Article 9  Article 10  \n",
      "abbasi   0.000000        0.0   0.000000    0.000000  \n",
      "abide    0.000000        0.0   0.000000    0.000000  \n",
      "about    2.704748        0.0   0.000000    0.000000  \n",
      "accord   0.000000        0.0   0.000000    0.000000  \n",
      "add      0.000000        0.0   2.299283    0.000000  \n",
      "...           ...        ...        ...         ...  \n",
      "world    0.000000        0.0   0.000000    0.000000  \n",
      "would    0.000000        0.0   2.299283    0.000000  \n",
      "year     0.000000        0.0   0.000000    0.000000  \n",
      "yi       0.000000        0.0   0.000000    5.409496  \n",
      "yuan     0.000000        0.0   0.000000    5.409496  \n",
      "\n",
      "[353 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  df_tf_idf = pd.DataFrame(tfidf_scores_transformed.T.todense(), index=feature_names, columns=article_index)\n",
    "  print(df_tf_idf)\n",
    "except:\n",
    "  pass\n",
    "\n",
    "try:\n",
    "  df_tf_idf = pd.DataFrame(tfidf_scores.T.todense(), index=feature_names, columns=article_index)\n",
    "  print(df_tf_idf)\n",
    "except:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eafc101",
   "metadata": {},
   "source": [
    "## Get highest scoring tf-idf term for each article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "95803f47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article 1    fare\n",
      "dtype: object\n",
      "Article 2    hong\n",
      "dtype: object\n",
      "Article 3    sugar\n",
      "dtype: object\n",
      "Article 4    petrol\n",
      "dtype: object\n",
      "Article 5    engine\n",
      "dtype: object\n",
      "Article 6    australia\n",
      "dtype: object\n",
      "Article 7    car\n",
      "dtype: object\n",
      "Article 8    railway\n",
      "dtype: object\n",
      "Article 9    cabinet\n",
      "dtype: object\n",
      "Article 10    china\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,11):\n",
    "  print(df_tf_idf[[f'Article {i}']].idxmax())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36c41e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
